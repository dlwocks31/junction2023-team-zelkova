import { NextApiRequest, NextApiResponse } from "next";
import OpenAI from "openai";

const openai = new OpenAI();

const restaurantPrompt = `BBQì¹˜í‚¨ ë‚™ì„±ëŒ€ì  / id 2 / ê±°ë¦¬ 0.7km / í‰ì  4.2
BBQì¹˜í‚¨ ì„œìš¸ëŒ€ì…êµ¬ì—­ì  / id 3 / ê±°ë¦¬ 2.3km / í‰ì  4.7
ë„ë¯¸ë…¸í”¼ì ì„œìš¸ëŒ€ì…êµ¬ì—­ì  / id 5 / ê±°ë¦¬ 1.1km / í‰ì  4.7
í”¼ìí—› ë¶€ì‚°ì„¼í…€ì  / id 7 / ê±°ë¦¬ 1.0km / í‰ì  2.3
í”¼ìì•Œë³¼ë¡œ í•´ìš´ëŒ€ì  / id 11 / ê±°ë¦¬ 4.1km / í‰ì  4.1
ë‚™ì„±ë°±ë°˜ / id 13 / ê±°ë¦¬ 0.5km / í‰ì  4.8`;

const systemIDSuggestPrompt = `ë‹¹ì‹ ì€ ìœ ì €ì—ê²Œ ì‹ë‹¹ì„ ì¶”ì²œí•´ì£¼ëŠ” ì±—ë´‡ì…ë‹ˆë‹¤. ìœ ì €ê°€ ìŒì‹ê³¼ ë¬´ê´€í•œ ë©”ì„¸ì§€ë¥¼ ë³´ë‚´ë©´ ê±°ì ˆí•´ì•¼ í•©ë‹ˆë‹¤.
í˜„ì¬ ìœ ì € ì£¼ë³€ì—ëŠ” ì•„ë˜ì™€ ê°™ì€ ì‹ë‹¹ì´ ìˆìŠµë‹ˆë‹¤:

${restaurantPrompt}

ìœ ì €ê°€ ì‹ë‹¹ ì¶”ì²œì„ ìš”ì²­í•˜ë©´, ìœ ì €ê°€ ì›í•˜ëŠ” ì¡°ê±´ì— ë§ëŠ” ì‹ë‹¹ ì´ë¦„ì„ JSONìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”. ìœ ì €ê°€ ìš”ì²­í•œ ì¢…ë¥˜ì˜ ìŒì‹ê³¼ ë‹¤ë¥¸ ì¢…ë¥˜ì˜ ì‹ë‹¹ì„ ì¶œë ¥í•˜ì§€ ì•Šì•„ì•¼ í•©ë‹ˆë‹¤.

ì•„ë˜ëŠ” ëŒ€í™” ì˜ˆì‹œì…ë‹ˆë‹¤.
User:
í”¼ì ë¨¹ê³ ì‹¶ì–´. í‰ì  ë†’ì€ ê³³ìœ¼ë¡œ
Assistant:
{name: ["ë„ë¯¸ë…¸í”¼ì ì„œìš¸ëŒ€ì…êµ¬ì—­ì ", "í”¼ìí—› ë¶€ì‚°ì„¼í…€ì ", "í”¼ìì•Œë³¼ë¡œ í•´ìš´ëŒ€ì "]}

User:
ë¡œë²„íŠ¸ëŠ” ì–¼ë§ˆë‚˜ ì¢‹ì•˜ì„ê¹Œ?
Assistant:
ì‹ë‹¹ ì¶”ì²œ ì™¸ì˜ ë‚´ìš©ì€ ë„ì™€ì¤„ ìˆ˜ ì—†ì–´. ì—¬ê¸° ê·¼ì²˜ ë§›ì§‘ ì •ë³´ ì›í•˜ë©´ ë§í•´! ğŸ˜†
`;

const systemDialoguePrompt = `ë‹¹ì‹ ì€ ìœ ì €ì—ê²Œ ì‹ë‹¹ì„ ì¶”ì²œí•´ì£¼ëŠ” ì±—ë´‡ì…ë‹ˆë‹¤. ìœ ì €ì˜ ì§ˆë¬¸ì— ëŒ€í•´ "XXXë¥¼ ë¨¹ê³  ì‹¶êµ°! XXXì„ ê°€ì ¸ì™”ì–´ ğŸ¤­" í˜•ì‹ì˜ ë©˜íŠ¸ë¥¼ ì¶œë ¥í•˜ì„¸ìš”. í˜•ì‹ ì™¸ì—ëŠ” ì•„ë¬´ê²ƒë„ ì¶œë ¥í•˜ì§€ ë§ˆì„¸ìš”. ì¹œê·¼í•˜ê²Œ ë°˜ë§ì„ ì‚¬ìš©í•˜ì„¸ìš”.

ì•„ë˜ëŠ” ëŒ€í™” ì˜ˆì‹œì…ë‹ˆë‹¤.
User:
í”¼ì ë¨¹ê³ ì‹¶ì–´. í‰ì  ë†’ì€ ê³³ìœ¼ë¡œ
Assistant:
í‰ì ì´ ë†’ì€ í”¼ìë¥¼ ë¨¹ê³  ì‹¶êµ°! ê´œì°®ì€ í”¼ìì§‘ì„ ê°€ì ¸ì™”ì–´ ğŸ¤­
`;

export default async function handler(
  req: NextApiRequest,
  res: NextApiResponse
) {
  const body = await req.json();
  const { type } = body;
  console.log(type);
  const systemPrompt =
    type === "id-suggest" ? systemIDSuggestPrompt : systemDialoguePrompt;
  const encoder = new TextEncoder();

  const readable = new ReadableStream({
    async start(controller) {
      const stream = await openai.chat.completions.create({
        messages: [
          {
            role: "system",
            content: systemPrompt,
          },
          {
            role: "user",
            content: "ì¹˜í‚¨ì„ ë¨¹ê³  ì‹¶ì–´. í‰ì  ë†’ì€ ê³³ìœ¼ë¡œ ì•Œë ¤ì¤˜",
          },
        ],
        model: "gpt-3.5-turbo",
        stream: true,
      });
      for await (const part of stream) {
        const content = part.choices[0]?.delta.content;
        if (content) {
          console.log(content);
          controller.enqueue(encoder.encode(content));
        }
      }
      controller.close();
    },
  });

  return new Response(readable, {
    headers: { "Content-Type": "text/html; charset=utf-8" },
  });
}

export const config = {
  runtime: "edge",
};
